{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tftables\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import data_loader\n",
    "import model_short as model\n",
    "import toy_data_loader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hps:\n",
    "    pass\n",
    "hps.n_levels = 3 # number of splits\n",
    "hps.depth = 3 # number of layers in revnet\n",
    "hps.width = 16 # channels in revnet layers\n",
    "hps.polyak_epochs = 1\n",
    "hps.beta1 = .9 # learning rate annealing factor\n",
    "hps.weight_decay = 1 # learning rate annealing factor\n",
    "hps.lr = .001 # base learning rate\n",
    "hps.n_data = 16000 # number of input spectra\n",
    "hps.batch_size = 50 # number of spectra in a batch\n",
    "hps.n_batches = int(hps.n_data / hps.batch_size)\n",
    "hps.n_bins = 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real or toy data by uncommenting the appropriate line\n",
    "# real data must have n_data=8000, n_bins=40000\n",
    "#input_stream, initialize_input_stream, data_init = data_loader.create_data_loader(\n",
    "input_stream, initialize_input_stream, data_init = toy_data_loader.create_data_loader(\n",
    "    sess, hps.batch_size, hps.n_data, hps.n_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data_init.shape)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for spectrum in data_init[:5]:\n",
    "    plt.plot(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    m = model.model(sess, hps, input_stream, data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m.train(.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_processed = 0\n",
    "\n",
    "hps.epochs = 20\n",
    "hps.epochs_warmup = 1\n",
    "hps.print_freq = 10\n",
    "\n",
    "for epoch in tqdm(range(1, hps.epochs + 1), desc='Epochs'):\n",
    "    train_results = []\n",
    "    initialize_input_stream()\n",
    "    with tqdm(total=hps.n_batches) as pbar:\n",
    "        for iteration in range(hps.n_batches):\n",
    "            pbar.set_description('Epoch ' + str(epoch))\n",
    "            lr = hps.lr * min(1., n_processed / (hps.batch_size * hps.n_batches * hps.epochs_warmup))\n",
    "            train_results += [m.train(lr)]\n",
    "            n_processed += hps.batch_size\n",
    "            pbar.set_postfix(lr=lr, loss=np.mean(train_results))\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, hps.batch_size)\n",
    "spectrum = data_init[i:i+1, :, :]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latent_rep = m.encode(spectrum)\n",
    "reconstruction = m.decode(latent_rep)\n",
    "print(latent_rep.mean(), latent_rep.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(latent_rep.shape[-1]):\n",
    "    plt.plot(latent_rep[0, :, channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(reconstruction))\n",
    "plt.plot(np.squeeze(spectrum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.squeeze(np.clip(reconstruction, 0, 1)))\n",
    "plt.plot(np.squeeze(spectrum))\n",
    "#plt.xlim(12000, 14000)\n",
    "plt.xlim(hps.n_bins*.475, hps.n_bins*.525)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.squeeze(np.clip(reconstruction, 0, 1)) - np.squeeze(spectrum))\n",
    "#plt.xlim(12000, 14000)\n",
    "plt.xlim(hps.n_bins*.475, hps.n_bins*.525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a corner plot with 4 components of the latent representation\n",
    "latent_reps = np.empty([0, 2500])\n",
    "initialize_input_stream()\n",
    "with tqdm(total=hps.n_batches) as pbar:\n",
    "    for _ in range(hps.n_batches):\n",
    "        data = sess.run(input_stream)\n",
    "        latent_rep = m.encode(data)\n",
    "        latent_reps = np.append(latent_reps, latent_rep[:, :, 0], axis=0) # select all channels of one component\n",
    "        pbar.set_postfix(mean=latent_reps.mean(), std=latent_reps.std())\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = 700\n",
    "components = 8\n",
    "print(latent_reps.shape)\n",
    "print(latent_reps[:, start_position:start_position + components].mean(axis=0))\n",
    "print(latent_reps[:, start_position:start_position + components].std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(latent_reps[:, start_position:start_position + components], \n",
    "                       range=components*[(-.5, .5)])\n",
    "\n",
    "axes = np.array(figure.axes).reshape((components, components))\n",
    "for yi in range(components):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.axvline(0, color=\"g\")\n",
    "        ax.axhline(0, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(latent_reps[:, 700], bins=[-1.5, -1, -.5, -.25, 0, .5, 1, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.restore('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glowenv",
   "language": "python",
   "name": "glowenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
